# Dynamic Excitability Enhances Robustness and Capacity in Recurrent Neural Networks

This repository contains the **MATLAB** code (and optional cached outputs) used to reproduce the results reported in the manuscript:

**Dynamic excitability enhances robustness and capacity in recurrent neural networks**  
(submitted to *PNAS Nexus*)

The codebase includes:
- **Classical Hopfield** networks with fixed thresholds
- Networks with **dynamic, activity-dependent thresholds** parameterized by \(\gamma\) and \(\beta\)
- Rate-based and spiking (**leaky integrate-and-fire, LIF**) formulations
- Noise-free and noisy regimes
- Standard performance metrics (e.g., recall accuracy / overlap, robustness, convergence dynamics)

---

## Repository structure

A suggested (and recommended) layout is below. The key convention is that **each manuscript figure is generated by a script named `figXX_generate_*.m`**.

```
.
├── code/
│   ├── figures/
│   │   ├── fig01_generate_overview.m
│   │   ├── fig02_generate_classical_hopfield.m
│   │   ├── fig03_generate_spiking_hopfield.m
│   │   ├── fig04_generate_spiking_dynamics.m
│   │   ├── fig05_generate_spiking_performance.m
│   │   └── figS01_generate_model_definition.m
│   │
│   ├── simulations/
│   │   └── reproduce_figures.m
│   │
│   ├── models/
│   ├── utils/
│   └── parameters/
│
├── data/
│   ├── raw/
│   └── processed/
│
├── figures_out/
│   ├── main/
│   └── supplementary/
│
└── README.md
```

**Naming rule (MATLAB):** the `.m` file name should match the main function name.

---

## Requirements

- MATLAB R2021a or later (tested with MATLAB R2022b)
- No proprietary toolboxes required beyond core MATLAB

Runtime scales with network size and parameter sweeps; large runs may take hours on a workstation.

---

## Quick start

### Reproduce all manuscript figures

From the repository root:

```matlab
cd code/simulations
reproduce_figures
```

By default, scripts should:
- set explicit random seeds (for deterministic runs)
- write figure files into `figures_out/`
- optionally cache intermediate results into `data/processed/`

### Generate a single figure

Example (adjust to your filenames):

```matlab
cd code/figures
fig02_generate_classical_hopfield
```

---

## Model summary (brief)

Binary patterns are stored using Hebbian connectivity:

\[
W = \frac{1}{N}\sum_\mu \xi^\mu (\xi^\mu)^\top.
\]

Dynamic thresholds are defined (manuscript notation) by:

\[
\theta_i = \gamma\, \frac{\mathbf{s}^\top W\mathbf{s}}{N}\, s_i + \beta\, d_i,
\]

where the first term is a global, parallel component and the second term introduces controlled heterogeneity.

Full definitions, numerical schemes, and parameter values are documented in the manuscript and Supplementary Information.

---

## Data and code availability

- **Code:** all MATLAB source code required to reproduce the figures is (or will be) contained in this repository.
- **Data:** figure-level outputs can be regenerated from code. If precomputed datasets are included, they will be stored under `data/`.

Upon acceptance, a permanent archival copy of this repository will be deposited in a public repository (e.g., Zenodo or Code Ocean) and assigned a DOI; the DOI will be added here and cited in the manuscript.

---

## Use of AI tools

If generative AI tools were used to draft or edit manuscript text, this will be disclosed in the manuscript (Materials and Methods or Acknowledgments) with tool name and model/version. All scientific content, code, analyses, and conclusions were produced and verified by the authors.

---

## License

MIT License (recommended for broad reuse). If you intend a different license, replace this section and add a `LICENSE` file.

---

## Citation

If you use this code, please cite:

Savchenko L. *et al.* Dynamic excitability enhances robustness and capacity in recurrent neural networks. *PNAS Nexus* (under review).

(Citation details will be updated upon publication.)

---

## Contact

Leonid Savchenko, University College London  
Email: savtchenko@yahoo.com
