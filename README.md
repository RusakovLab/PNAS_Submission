# Dynamic Excitability Enhances Robustness and Capacity in Recurrent Neural Networks

This repository contains the code and data used to generate the results reported in the manuscript:

**Dynamic excitability enhances robustness and capacity in recurrent neural networks**  
(submitted to *PNAS Nexus*)

The repository provides reproducible implementations of classical Hopfield networks and extended models with adaptive (γ/β-dependent) excitability, including both rate-based and spiking neuron formulations.

---

## Overview

The code implements and compares:

- Classical Hopfield networks with fixed thresholds
- Recurrent networks with **dynamic, activity-dependent thresholds**
- Rate-based and spiking (leaky integrate-and-fire) neuron models
- Noise-free and noisy operating regimes
- Performance metrics including recall accuracy, robustness to noise, and convergence dynamics

All figures reported in the manuscript are generated using the scripts provided here.

---

## Repository Structure

